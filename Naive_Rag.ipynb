{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jai8004/Av-tuts/blob/main/Naive_Rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ESqC6wiqLVD"
      },
      "outputs": [],
      "source": [
        "# store openapi key in oracle_api_key  in secrets colab\n",
        "from google.colab import userdata\n",
        "import os\n",
        "os.apikey = userdata.get('nexusiqkey_F06752')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OFcdnflk5eC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCBwZ7_iqhbA",
        "outputId": "8a27a080-f7f1-443d-e90a-a4add8335b23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.42 (from langchain_openai)\n",
            "  Downloading langchain_core-0.3.43-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.61.1)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (0.3.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (2.10.6)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain_openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.42->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain_openai) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain_openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.42->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.42->langchain_openai) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.3.0)\n",
            "Downloading langchain_openai-0.3.8-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.43-py3-none-any.whl (415 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.4/415.4 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, langchain-core, langchain_openai\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.41\n",
            "    Uninstalling langchain-core-0.3.41:\n",
            "      Successfully uninstalled langchain-core-0.3.41\n",
            "Successfully installed langchain-core-0.3.43 langchain_openai-0.3.8 tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -U langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ijv1yfquL05",
        "outputId": "94d534e7-4bfd-47cd-f45a-c621653b22cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.19-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.43)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.20 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.20)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.11)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.20->langchain-community) (0.3.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.20->langchain-community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.20->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.20->langchain-community) (2.27.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.19-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.19 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UfFdR681BiT",
        "outputId": "623e922c-8102-48f0-c1ce-229020afc677"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-5.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Downloading pypdf-5.3.1-py3-none-any.whl (302 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/302.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('nexusiqkey_F06752')\n",
        "llm = ChatOpenAI(model =\"gpt-4o-mini\")\n",
        "llm.invoke(\"hi, What is Vaughan is saying about champions trophy\").content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "u3xrzGxbqgy-",
        "outputId": "be46a3b9-defe-4fe3-fcca-9b52e352c5bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"As of my last update in October 2023, I don't have access to real-time information or statements from individuals. If you're referring to former England cricketer Michael Vaughan, he often shares his opinions on cricket events, including tournaments like the ICC Champions Trophy, through social media or other platforms. \\n\\nTo find Vaughn's latest thoughts on the Champions Trophy, I recommend checking his Twitter account, sports news websites, or cricket analysis platforms for the most current insights and commentary. If you need a summary of any historical context or past comments related to the Champions Trophy or Vaughan's views, feel free to ask!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"hi, which country won champion's tropee 2025?\").content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "VI221HRGqcft",
        "outputId": "e67634f3-b828-4698-a6fa-6bf396a5f0e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'As of my last update in October 2023, I do not have information on the winner of the ICC Champions Trophy 2025, as the event had not yet occurred. For the most accurate and up-to-date information, please check a reliable sports news source or the official ICC website.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: implement RAg by using langchain and using in memory vector store\n",
        "\n",
        "from google.colab import userdata\n",
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "# from langchain.vectorstores import InMemoryDocstore\n",
        "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import TextLoader\n",
        "# store openapi key in oracle_api_key  in secrets colab\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('nexusiqkey_F06752')\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "# Example documents (replace with your actual documents)\n",
        "sample_doc = \"\"\"\n",
        "NEW DELHI: Former England captain Michael Vaughan has heaped praise on India’s extraordinary bench strength following their historic ICC Champions Trophy victory over New Zealand on Sunday.\n",
        "Taking to X (formerly Twitter), Vaughan suggested that even a second-string Indian side could have reached the final.\n",
        "“Jaiswal, Varma, Sharma, SKY, Pant, Reddy, Sundar, Chahal, Arshdeep, Bumrah & Bishnoi… This team would have made it to the final as well IMO. The strength in Indian cricket in white-ball is off the scale,” he wrote.\n",
        "\"\"\"\n",
        "# Create a document loader\n",
        "loader = TextLoader(file_path='/content/sample_doc.txt') # Dummy filepath, content will be directly used\n",
        "#  Write the sample doc to the dummy file\n",
        "with open(\"/content/sample_doc.txt\",\"w\") as f:\n",
        "  f.write(sample_doc)\n",
        "documents = loader.load()\n",
        "# Split the document into chunks\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "# Create embeddings\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# Create vector store\n",
        "docsearch = InMemoryDocstore({d.page_content: d for d in docs})#InMemoryDocstore(embeddings.embed_query).from_documents(documents)\n",
        "\n",
        "from langchain.retrievers import SVMRetriever\n",
        "retriever = SVMRetriever.from_texts(\n",
        "    texts=[d.page_content for d in docs],\n",
        "    embeddings=embeddings,\n",
        "    docstore=docsearch\n",
        ")\n",
        "\n",
        "# Create the chain\n",
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
        "\n",
        "# Example queries\n",
        "query1 = \"hi, What is Vaughan is saying about champions trophy\"\n",
        "result1 = qa.run(query1)\n",
        "print(f\"Query 1 Result: {result1}\")\n",
        "\n",
        "query2 = \"hi, which country won champion's tropee 2025?\"\n",
        "result2 = qa.run(query2)\n",
        "print(f\"Query 2 Result: {result2}\")\n"
      ],
      "metadata": {
        "id": "Qzn3i554s1kc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad6eff1e-f522-4100-ce97-47c5cd555f50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-a33d77f2c087>:51: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  result1 = qa.run(query1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query 1 Result: Michael Vaughan is praising India's bench strength in cricket following their victory in the ICC Champions Trophy. He suggested that even a second-string Indian team, which includes players like Jaiswal, Varma, Sharma, and others, could have reached the final of the tournament. He highlighted the impressive depth of talent in Indian white-ball cricket.\n",
            "Query 2 Result: I don't know.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: implement RAg by using langchain and using in memory vector store\n",
        "\n",
        "from google.colab import userdata\n",
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "# from langchain.vectorstores import InMemoryDocstore\n",
        "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import TextLoader\n",
        "# store openapi key in oracle_api_key  in secrets colab\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('nexusiqkey_F06752')\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "# Example documents (replace with your actual documents)\n",
        "# sample_doc = \"\"\"\n",
        "# NEW DELHI: Former England captain Michael Vaughan has heaped praise on India’s extraordinary bench strength following their historic ICC Champions Trophy victory over New Zealand on Sunday.\n",
        "# Taking to X (formerly Twitter), Vaughan suggested that even a second-string Indian side could have reached the final.\n",
        "# “Jaiswal, Varma, Sharma, SKY, Pant, Reddy, Sundar, Chahal, Arshdeep, Bumrah & Bishnoi… This team would have made it to the final as well IMO. The strength in Indian cricket in white-ball is off the scale,” he wrote.\n",
        "# \"\"\"\n",
        "# Create a document loader\n",
        "loader = TextLoader(file_path='/content/Nayan_CV.txt') # Dummy filepath, content will be directly used\n",
        "#  Write the sample doc to the dummy file\n",
        "# with open(\"/content/sample_doc.txt\",\"w\") as f:\n",
        "#   f.write(sample_doc)\n",
        "documents = loader.load()\n",
        "# Split the document into chunks\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "# Create embeddings\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# Create vector store\n",
        "docsearch = InMemoryDocstore({d.page_content: d for d in docs})#InMemoryDocstore(embeddings.embed_query).from_documents(documents)\n",
        "\n",
        "from langchain.retrievers import SVMRetriever\n",
        "retriever = SVMRetriever.from_texts(\n",
        "    texts=[d.page_content for d in docs],\n",
        "    embeddings=embeddings,\n",
        "    docstore=docsearch\n",
        ")\n",
        "\n",
        "# Create the chain\n",
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
        "\n",
        "# Example queries\n",
        "query1 = \"hi, What is Nayan's Total experience?\"\n",
        "result1 = qa.run(query1)\n",
        "print(f\"Query 1 Result: {result1}\")\n",
        "\n",
        "query2 = \"hi, What are Nayan's core skills??\"\n",
        "result2 = qa.run(query2)\n",
        "print(f\"Query 2 Result: {result2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i24if-lOt-cN",
        "outputId": "82398a3d-7d60-4b96-83a2-201e3b2c5819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query 1 Result: Nayan Agrawal has a total of approximately 5 years of work experience. They worked as a Graduate Engineer Trainee from June 2018 to May 2019 and have been a Product Design Manager since June 2019, currently still in that role as of October 2023.\n",
            "Query 2 Result: Nayan's core skills include:\n",
            "\n",
            "- Machine Learning\n",
            "- Deep Learning\n",
            "- Natural Language Processing (NLP)\n",
            "- Feature Engineering\n",
            "\n",
            "Additionally, he is proficient in various tools such as Python, SQL, Power-BI, FastAPI, Flask, Django, Scikit-Learn, TensorFlow, OpenCV, and DialogFlow.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: implement RAg by using langchain and using in memory vector store\n",
        "\n",
        "from google.colab import userdata\n",
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "# from langchain.vectorstores import InMemoryDocstore\n",
        "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
        "\n",
        "\n",
        "# store openapi key in oracle_api_key  in secrets colab\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('nexusiqkey_F06752')\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "# Example documents (replace with your actual documents)\n",
        "# sample_doc = \"\"\"\n",
        "# NEW DELHI: Former England captain Michael Vaughan has heaped praise on India’s extraordinary bench strength following their historic ICC Champions Trophy victory over New Zealand on Sunday.\n",
        "# Taking to X (formerly Twitter), Vaughan suggested that even a second-string Indian side could have reached the final.\n",
        "# “Jaiswal, Varma, Sharma, SKY, Pant, Reddy, Sundar, Chahal, Arshdeep, Bumrah & Bishnoi… This team would have made it to the final as well IMO. The strength in Indian cricket in white-ball is off the scale,” he wrote.\n",
        "# \"\"\"\n",
        "# Create a document loader\n",
        "loader = PyPDFLoader(file_path='Nayan Agrawal CV.pdf')\n",
        "# loader = TextLoader(file_path='/content/Nayan_CV.txt') # Dummy filepath, content will be directly used\n",
        "#  Write the sample doc to the dummy file\n",
        "# with open(\"/content/sample_doc.txt\",\"w\") as f:\n",
        "#   f.write(sample_doc)\n",
        "documents = loader.load()\n",
        "# Split the document into chunks\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "# Create embeddings\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# Create vector store\n",
        "docsearch = InMemoryDocstore({d.page_content: d for d in docs})#InMemoryDocstore(embeddings.embed_query).from_documents(documents)\n",
        "\n",
        "from langchain.retrievers import SVMRetriever\n",
        "retriever = SVMRetriever.from_texts(\n",
        "    texts=[d.page_content for d in docs],\n",
        "    embeddings=embeddings,\n",
        "    docstore=docsearch\n",
        ")\n",
        "\n",
        "# Create the chain\n",
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
        "\n",
        "# Example queries\n",
        "query1 = \"hi, What is Nayan's Total experience?\"\n",
        "result1 = qa.run(query1)\n",
        "print(f\"Query 1 Result: {result1}\")\n",
        "\n",
        "query2 = \"hi, What are Nayan's core skills??\"\n",
        "result2 = qa.run(query2)\n",
        "print(f\"Query 2 Result: {result2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QngdtxQjxhJe",
        "outputId": "3ba1bfb4-08cd-41f2-8972-7fee2455a44b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-3f62eb9107e0>:38: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
            "  embeddings = OpenAIEmbeddings()\n",
            "<ipython-input-3-3f62eb9107e0>:55: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  result1 = qa.run(query1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query 1 Result: Nayan has a total work experience of about 1 year and 4 months. They worked as a Graduate Engineer Trainee from June 2018 to May 2019 and have been a Product Design Manager since June 2019, continuing in that role to the present.\n",
            "Query 2 Result: Nayan's core skills include:\n",
            "\n",
            "- Machine Learning\n",
            "- Deep Learning\n",
            "- Natural Language Processing (NLP)\n",
            "- Feature Engineering\n",
            "\n",
            "He also has experience with various tools such as Python, SQL, Power-BI, FastAPI, Flask, Django, Scikit-Learn, TensorFlow, OpenCV, and DialogFlow.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dR3I--_E07FP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}